{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "\n",
    "# Author(s): Kevin P. Murphy (murphyk@gmail.com) and Mahmoud Soliman (mjs@aucegypt.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/figures//chapter4_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloning the pyprobml repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/probml/pyprobml \n",
    "%cd pyprobml/scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing required software (This may take few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install octave  -qq > /dev/null\n",
    "!apt-get install liboctave-dev -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "DISCLAIMER = 'WARNING : Editing in VM - changes lost after reboot!!'\n",
    "from google.colab import files\n",
    "\n",
    "def interactive_script(script, i=True):\n",
    "  if i:\n",
    "    s = open(script).read()\n",
    "    if not s.split('\\n', 1)[0]==\"## \"+DISCLAIMER:\n",
    "      open(script, 'w').write(\n",
    "          f'## {DISCLAIMER}\\n' + '#' * (len(DISCLAIMER) + 3) + '\\n\\n' + s)\n",
    "    files.view(script)\n",
    "    %run $script\n",
    "  else:\n",
    "      %run $script\n",
    "\n",
    "def show_image(img_path):\n",
    "  from google.colab.patches import cv2_imshow\n",
    "  import cv2\n",
    "  img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "  img=cv2.resize(img,(600,600))\n",
    "  cv2_imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.1:<a name='4.1'></a> <a name='fig:irisCorr'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Covariance matrix for the features in the iris dataset from \\cref  sec:iris . (b) Correlation matrix. We only show the lower triangle, since the matrix is symmetric and has a unit diagonal. Compare this to \\cref  fig:irisPairs .  \n",
    "Figure(s) generated by [iris_cov_mat.py](https://github.com/probml/pyprobml/blob/master/scripts/iris_cov_mat.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"iris_cov_mat.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.2:<a name='4.2'></a> <a name='hingeLoss'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of various loss functions for binary classification. The horizontal axis is the margin $z=\\cc@accent  \"707E  y \\eta $, the vertical axis is the loss. The log loss uses log base 2.  \n",
    "Figure(s) generated by [hinge_loss_plot.py](https://github.com/probml/pyprobml/blob/master/scripts/hinge_loss_plot.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"hinge_loss_plot.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.3:<a name='4.3'></a> <a name='covshrinkDemo'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Estimating a covariance matrix in $D=50$ dimensions using $N \\in \\ 100, 50, 25\\ $ samples. We plot the eigenvalues in descending order for the true covariance matrix (solid black), the MLE (dotted blue) and the MAP estimate (dashed red), using \\cref  eqn:covShrinkLedoit  with $\\lambda =0.9$. We also list the condition number of each matrix in the legend. We see that the MLE is often poorly conditioned, but the MAP estimate is numerically well behaved. Adapted from Figure 1 of <a href='#Schafer05'>[SS05]</a> .  \n",
    "Figure(s) generated by [shrinkcov_plots.py](https://github.com/probml/pyprobml/blob/master/scripts/shrinkcov_plots.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"shrinkcov_plots.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.4:<a name='4.4'></a> <a name='fig:polyfitRidge'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a-c) Ridge regression applied to a degree 14 polynomial fit to 21 datapoints. (d) MSE vs strength of regularizer. The degree of regularization increases from left to right, so model complexity decreases from left to right.  \n",
    "Figure(s) generated by [linreg_poly_ridge.py](https://github.com/probml/pyprobml/blob/master/scripts/linreg_poly_ridge.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"linreg_poly_ridge.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.5:<a name='4.5'></a> <a name='cv'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Schematic of 5-fold cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"/content/pyprobml/notebooks/figures/images/{kfold}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.6:<a name='4.6'></a> <a name='fig:polyfitRidgeVsLambda'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Ridge regression is applied to a degree 14 polynomial fit to 21 datapoints shown in \\cref  fig:polyfitRidge  for different values of the regularizer $\\lambda $. The degree of regularization increases from left to right, so model complexity decreases from left to right. (a) MSE on train (blue) and test (red) vs $\\qopname o log (\\lambda )$. (b) 5-fold cross-validation estimate of test MSE in red; error bars are standard error of the mean. In black we plot the negative log evidence $-\\qopname o log p( \\mathcal  D  |\\lambda )$. Both curves are scaled to lie in $[0,1]$.  \n",
    "Figure(s) generated by [polyfitRidgeModelSel.m](https://github.com/probml/pmtk3/blob/master/demos/polyfitRidgeModelSel.m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!octave -W polyfitRidgeModelSel.m >> _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.7:<a name='4.7'></a> <a name='fig:imdbperf'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Performance of a text classifier (a neural network applied to a bag of word embeddings using average pooling) vs number of training epochs on the IMDB movie sentiment dataset. Blue = train, red = validation. (a) Cross entropy loss. Early stopping is triggered at about epoch 25. (b) Classification accuracy.  \n",
    "Figure(s) generated by [imdb_mlp_bow_tf.py](https://github.com/probml/pyprobml/blob/master/scripts/imdb_mlp_bow_tf.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"imdb_mlp_bow_tf.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.8:<a name='4.8'></a> <a name='polyfitN'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  MSE on training and test sets vs size of training set, for data generated from a degree 2 polynomial with Gaussian noise of variance $\\sigma ^2=4$. We fit polynomial models of varying degree to this data.  \n",
    "Figure(s) generated by [linreg_poly_vs_n.py](https://github.com/probml/pyprobml/blob/master/scripts/linreg_poly_vs_n.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"linreg_poly_vs_n.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4.9:<a name='4.9'></a> <a name='fig:EMA'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of exponentially-weighted moving average with and without bias correction. (a) Short memory: $\\beta =0.9$. (a) Long memory: $\\beta =0.99$.  \n",
    "Figure(s) generated by [ema_demo.py](https://github.com/probml/pyprobml/blob/master/scripts/ema_demo.py) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_script(\"ema_demo.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='Schafer05'>[SS05]</a> J. Schaefer and K. Strimmer. \"A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics\". In: Statist. Appl. Genet. Mol. Biol (2005). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
