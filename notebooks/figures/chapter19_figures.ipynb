{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "# Use of this source code is governed by an MIT-style\n",
    "# license that can be found in the LICENSE file or at\n",
    "# https://opensource.org/licenses/MIT.\n",
    "\n",
    "# Author(s): Kevin P. Murphy (murphyk@gmail.com) and Mahmoud Soliman (mjs@aucegypt.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://opensource.org/licenses/MIT\" target=\"_parent\"><img src=\"https://img.shields.io/github/license/probml/pyprobml\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/probml/pyprobml/blob/master/notebooks/figures//chapter19_figures.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.1:<a name='19.1'></a> <a name='chollet-cat-crops'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of random crops, zooms and rotations of some cat images. From \\cite  kerasBook . Used with kind permission of Francois Chollet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/chollet-cat-crops.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.2:<a name='19.2'></a> <a name='transfer'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of transfer learning from dataset $ \\mathcal  D  _p$ to $ \\mathcal  D  _q$ using a neural network, in which the feature extractor is shared, but the final layer is domain specific. The parameters $\\boldsymbol  \\theta  _1$ are first trained on $ \\mathcal  D  _p$, and then optionally fine-tuned on $ \\mathcal  D  _q$. Thus the information in $ \\mathcal  D  _p$ is used to help the model work well on $ \\mathcal  D  _q$, but not vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/transfer.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.3:<a name='19.3'></a> <a name='supervisedImputation'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Context encoder for self-supervised learning. From <a href='#Pathak2016'>[Dee+16]</a> . Used with kind permission of Deepak Pathak. (b) Some other proxy tasks for self-supervised learning. From <a href='#LeCunSSL2018'>[LeC18]</a> . Used with kind permission of Yann LeCun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/context-encoder.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/self-sup-lecun.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.4:<a name='19.4'></a> <a name='simCLRcrop'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  (a) Illustration of SimCLR training. $\\mathcal  T $ is a set of stochastic semantics-preserving transformations (data augmentations). (b-c) Illustration of the benefit of random crops. Solid rectangles represent the original image, dashed rectangles are random crops. On the left, the model is forced to predict the local view A from the global view B (and vice versa). On the right, the model is forced to predict the appearance of adjacent views (C,D). From Figures 2--3 of <a href='#chen2020simple'>[Tin+20]</a> . Used with kind permission of Ting Chen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.5:<a name='19.5'></a> <a name='simCLR'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Visualization of SimCLR training. Each input image in the minibatch is randomly modified in two different ways (using cropping (followed by resize), flipping, and color distortion), and then fed into a Siamese network. The embeddings (final layer) for each pair derived from the same image is forced to be close, whereas the embeddings for all other pairs are forced to be far. From   https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html . Used with kind permission of Ting Chen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/simCLRattract.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/simCLRrepel.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.6:<a name='19.6'></a> <a name='MAML-PGM'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Graphical model corresponding to MAML. Left: generative model. Right: During meta-training, each of the task parameters $\\boldsymbol  \\theta  _j$'s are updated using their local datasets. The indices $j$ are over tasks (meta datasets), and $i$ are over instances within each task. Solid shaded nodes are always observed; semi-shaded (striped) nodes are only observed during meta training time (i.e., not at test time). From Figure 1 of <a href='#Finn2018'>[CKS18]</a> . Used with kind permission of Chelsea Finn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/PMAML2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.7:<a name='19.7'></a> <a name='metaLearningFSL'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of meta-learning for few-shot learning. Here, each task is a 3-way-2-shot classification problem because each training task contains a support set with three classes, each with two examples. From   https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i . Copyright (2019) Borealis AI. Used with kind permission of Simon Prince and April Cooper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/FSL-borealis-NC.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.8:<a name='19.8'></a> <a name='matchingNetworks'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of a matching network for one-shot learning. From Figure 1 of <a href='#Vinyals2016'>[Ori+16]</a> . Used with kind permission of Oriol Vinyals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/matchingNetworks.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.9:<a name='19.9'></a> <a name='cosineSim'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the cosine similarity between a query vector $\\mathbf  q $ and two document vectors $\\mathbf  d _1$ and $\\mathbf  d _2$. Since angle $\\alpha $ is less than angle $\\theta $, we see that the query is more similar to document 1. From   https://en.wikipedia.org/wiki/Vector_space_model . Used with kind permission of Wikipedia author Riclas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/Vector_space_model.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.10:<a name='19.10'></a> <a name='word2vec'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of word2vec model with window size $H=2$. (a) CBOW version. (b) Skip-gram version. . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/cbow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/skipgram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.11:<a name='19.11'></a> <a name='word2vecMath'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Visualization of arithmetic operations in word2vec embedding space. From   https://www.tensorflow.org/tutorials/representation/word2vec . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/word2vec-arithmetic.png.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.12:<a name='19.12'></a> <a name='elmo'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of ELMo bidrectional language model. Here $y_t=x_ t+1 $ when acting as the target for the forwards LSTM, and $y_t = x_ t-1 $ for the backwards LSTM. (We add \\text  \\em  bos  \\xspace and \\text  \\em  eos  \\xspace sentinels to handle the edge cases.) From Weng2019LM. Used with kind permission of Lilian Weng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/ELMo-biLSTM.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.13:<a name='19.13'></a> <a name='BERT'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of (a) GPT and (b) BERT. $E_t$ is the embedding vector for the input token at location $t$, and $T_t$ is the output target to be predicted. From Figure 3 of <a href='#bert'>[Jac+19]</a> . Used with kind permission of Ming-Wei Chang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/GPT-fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/BERT-fig.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.14:<a name='19.14'></a> <a name='bert-tasks'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how BERT can be used for different kinds of supervised NLP tasks. (a) Sentence-pair classification (e.g., entailment). (b) Single sentence classification (e.g., sentiment). (c) Sentence pair tagging (e.g., question answering). (d) Single sentence tagging (e.g., named entity recognition, where the tags are ``outside'', ``begin-person'', ``inside-person'', ``begin-place'', ``inside-place'', etc). From Figure 4 of <a href='#bert'>[Jac+19]</a> . Used with kind permission of Ming-Wei Chang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/bert-tasks-A.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/bert-tasks-B.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/bert-tasks-C.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/bert-tasks-D.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.15:<a name='19.15'></a> <a name='squad'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Question-answer pairs for a sample passage in the SQuAD dataset. Each of the answers is a segment of text from the passage. This can be solved using sentence pair tagging. The input is the paragraph text T and the question Q. The output is a tagging of the relevant words in T that answer the question in Q. From Figure 1 of <a href='#squad'>[Pra+16]</a> . Used with kind permission of Percy Liang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.16:<a name='19.16'></a> <a name='T5'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of how the T5 model (``Text-to-text Transfer Transformer'') can be used to perform multiple NLP tasks, such as translating English to German; determining if a sentence is linguistic valid or not ( \\bf CoLA  stands for ``Corpus of Linguistic Acceptability''); determining the degree of semantic similarity ( \\bf STSB  stands for ``Semantic Textual Similarity Benchmark''); and abstractive summarization. From Figure 1 of <a href='#T5'>[Col+19]</a> . Used with kind permission of Colin Raffel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/T5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.17:<a name='19.17'></a> <a name='SSL'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Illustration of the benefits of semi-supervised learning for a binary classification problem. Labeled points from each class are shown as black and white circles respectively. (a) Decision boundary we might learn given only unlabeled data. (b) Decision boundary we might learn if we also had a lot of unlabeled data points, shown as smaller grey circles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/SSL1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/SSL2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.18:<a name='19.18'></a> <a name='emvsst'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Comparison of the entropy minimization, self-training, and ``sharpened'' entropy minimization loss functions for a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/emvsst.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.19:<a name='19.19'></a> <a name='emgoodbad'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Visualization demonstrating how entropy minimization enforces the cluster assumption. The classifier assigns a higher probability to class 1 (black dots) or 2 (white dots) in red or blue regions respectively. The predicted class probabilities for one particular unlabeled datapoint is shown in the bar plot. In (a), the decision boundary passes through high-density regions of data, so the classifier is forced to output high-entropy predictions. In (b), the classifier avoids high-density regions and is able to assign low-entropy predictions to most of the unlabeled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/embad.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/emgood.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.20:<a name='19.20'></a> <a name='sevskl'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Comparison of the squared error and KL divergence lossses for a consistency regularization. This visualization is for a binary classification problem where it is assumed that the model's output for the unperturbed input is 1. The figure plots the loss incurred for a particular value of the logit (i.e.\\ the pre-activation fed into the output sigmoid nonlinearity) for the perturbed input. As the logit grows towards infinity, the model predicts a class label of 1 (in agreement with the prediction for the unperturbed input); as it grows towards negative infinity, the model predictions class 0. The squared error loss saturates (and has zero gradients) when the model predicts one class or the other with high probability, but the KL divergence grows without bound as the model predicts class 0 with more and more confidence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/sevskl.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.21:<a name='19.21'></a> <a name='ssgan'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Diagram of the semi-supervised GAN framework. The discriminator is trained to output the class of labeled datapoints (red), a ``fake'' label for outputs from the generator (yellow), and any label for unlabeled data (green). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/ssgan.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 19.22:<a name='19.22'></a> <a name='SimCLR2'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Combinng self-supervised learning on unlabeled data (left), supervised fine-tuning (middle), and self-training on pseudo-labeled data (right). From Figure 3 of <a href='#Chen2020nips'>[Tin+20]</a> . Used with kind permission of Ting Chen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "%%time\n",
    "# If you run this for the first time it would take ~25/30 seconds\n",
    "!git clone https://github.com/probml/pyprobml /pyprobml &> /dev/null && git clone https://github.com/Sekhen/colab_powertoys.git &> /dev/null \n",
    "!pip3 install nbimporter -qqq \n",
    "%cd -q /content/colab_powertoys \n",
    "from colab_powertoys.probml_toys import probml_toys as pmlt\n",
    "%cd -q /content/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmlt.show_image(\"/content/pyprobml/notebooks/figures/images/simCLR2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    " <a name='Finn2018'>[CKS18]</a> F. Chelsea, X. Kelvin and L. Sergey. \"Probabilistic Model-Agnostic Meta-Learning\". (2018). \n",
    "\n",
    "<a name='T5'>[Col+19]</a> R. Colin, S. Noam, R. Adam, L. LeeKatherine, N. Sharan, M. Michael, Z. ZhouYanqi, L. Wei and L. PeterJ. \"Exploring the Limits of Transfer Learning with a UnifiedText-to-Text Transformer\". abs/1910.10683 (2019). arXiv: 1910.10683 \n",
    "\n",
    "<a name='Pathak2016'>[Dee+16]</a> P. Deepak, K. Philipp, D. Jeff, D. Trevor and E. AlexeiA. \"Context Encoders: Feature Learning by Inpainting\". (2016). \n",
    "\n",
    "<a name='bert'>[Jac+19]</a> D. Jacob, C. Ming-Wei, L. Kenton and T. ToutanovaKristina. \"BERT: Pre-training of Deep Bidirectional Transformers forLanguage Understanding\". (2019). \n",
    "\n",
    "<a name='LeCunSSL2018'>[LeC18]</a> Y. LeCun \"Self-supervised learning: could machines learn like humans?\". (2018). \n",
    "\n",
    "<a name='Vinyals2016'>[Ori+16]</a> V. Oriol, B. Charles, L. Timothy, K. Koray and W. Daan. \"Matching Networks for One Shot Learning\". (2016). \n",
    "\n",
    "<a name='squad'>[Pra+16]</a> R. Pranav, Z. Jian, L. Konstantin and L. Percy. \"SQuAD: 100,000+ Questions for Machine Comprehension of Text\". (2016). \n",
    "\n",
    "<a name='Chen2020nips'>[Tin+20]</a> C. Ting, K. Simon, S. Kevin, N. NorouziMohammad and H. Geoffrey. \"Big Self-Supervised Models are Strong Semi-SupervisedLearners\". (2020). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
